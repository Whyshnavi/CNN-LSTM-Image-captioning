# CNN-LSTM-Image-captioning
A deep learning project that generates captions for images using a custom-built Convolutional Neural Network (CNN) for visual feature extraction and an LSTM network for sequence generationâ€”without relying on any pre-trained models.

ğŸ“¸ Project Overview
This project demonstrates how to build an image captioning system from the ground up, where both the image encoder (CNN) and language decoder (LSTM) are trained from scratch. The model learns to understand visual content and describe it in natural language.

ğŸ§± Model Architecture
CNN (Custom): Designed and trained from scratch to extract image features.

LSTM: Trained to generate sequences (captions) based on CNN-extracted features and previous words.

Embedding Layer: Converts tokens to dense word vectors.

Dense Output Layer: Predicts the next word in the sequence.

ğŸ—‚ Dataset
Flickr8k / Flickr30k / MS COCO

Each image has multiple human-annotated captions.

Preprocessing includes:

Lowercasing, removing punctuation

Tokenization and padding

Building vocabulary and word-index mappings

ğŸš€ Features
âœ… CNN built and trained from scratch

âœ… Custom tokenizer and caption preprocessing

âœ… Image feature extraction using custom CNN

âœ… Caption generation using LSTM

âœ… Evaluation using BLEU score

âœ… Support for Greedy and Beam Search decoding

ğŸ›  Technologies Used
Python
TensorFlow / Keras
NumPy, Pandas
NLTK / spaCy
Matplotlib
rough-score

ğŸ“ˆ Results
Metric	Score
BLEU-1	0.454458
BLEU-2	0.199821
BLEU-3	0.095696
BLEU-4	0.041299
METEOR  0.146983
ROUGH-L 0.227503
CIDEr   0.099939

(Replace with your actual scores once you have them)

ğŸ§ª How to Run
bash
Copy
Edit
# Clone the repository
git clone https://github.com//cnn-lstm-captioning-scratch.git
cd cnn-lstm-captioning-scratch

# Install dependencies
pip install -r requirements.txt

# Train the model
python train.py

# Generate captions
python generate_caption.py --image_path sample.jpg
ğŸ“ Project Structure
graphql
Copy
Edit
â”œâ”€â”€ data/               # Raw dataset and processed captions
â”œâ”€â”€ models/             # Saved CNN and LSTM model files
â”œâ”€â”€ utils/              # Utility scripts (tokenizer, data loader, etc.)
â”œâ”€â”€ train.py            # Main training script
â”œâ”€â”€ generate_caption.py # Caption generation for new images
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ¯ Future Enhancements
ğŸ” Add attention mechanism (e.g., Bahdanau)

ğŸ“ˆ Improve CNN architecture (e.g., more layers, batch norm)

ğŸš€ Integrate a web interface with Flask/Streamlit

ğŸ§  Experiment with Transformer-based decoders


ğŸ“¬ Contact
Whyshnavi Pathmanathan
ğŸ“§ Email: whyshnavi01@gmail.com
